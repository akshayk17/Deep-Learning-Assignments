{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "8IdVhvFAWjeI",
        "f8vw0fEFW9nR",
        "8ly0omJwXUrK",
        "7It07Qw0bGHU",
        "aVDy9pL-bWvN",
        "ZPMpEmI4dDFA",
        "KkJabarNdel5",
        "yFTLGqHMfin4",
        "qqJl-uvIgJil",
        "b9CeBVXphQBc",
        "0SDKn2t6ayrU",
        "z9U5UL4ra3he",
        "Jrbipjila6EP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9RC4cV6yWQYy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 1 - Assignment 2\n",
        "\n",
        "The model is based on the DCGAN structure to use for the given set of images.\n",
        "\n",
        "The code used PyTorch Deep Learning Framework and utilizes Binary Cross Entropy Function and Adam Optimizers with step-wise Learning-Rate Decay."
      ]
    },
    {
      "metadata": {
        "id": "8IdVhvFAWjeI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "ZUPkTnA_WDcJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8vw0fEFW9nR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Variable Declaration"
      ]
    },
    {
      "metadata": {
        "id": "KT1GeXYfXDPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "batchSize = 32\n",
        "imageSize = 64\n",
        "learning_rate = 0.001\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ly0omJwXUrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "7It07Qw0bGHU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Download and Organize Data"
      ]
    },
    {
      "metadata": {
        "id": "a1V17jEqZClf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://cswww.essex.ac.uk/mv/allfaces/faces94.zip\n",
        "!unzip faces94.zip\n",
        "!mkdir data\n",
        "!mv faces94/female/* data\n",
        "!mv faces94/male/* data\n",
        "!mv faces94/malestaff/* data\n",
        "!rm faces94.zip\n",
        "!rm -rf faces94\n",
        "!ls data | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aVDy9pL-bWvN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### DataLoader Declaration"
      ]
    },
    {
      "metadata": {
        "id": "82YFqA9jbmG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dataloader_function(datadir):\n",
        "  \n",
        "    data_transform = transforms.Compose([transforms.Resize((imageSize,imageSize)), transforms.ToTensor()])\n",
        "    dataset = datasets.ImageFolder(datadir, transform = data_transform)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle = True)\n",
        "    \n",
        "    return dataloader\n",
        "\n",
        "data_dir = 'data/'\n",
        "dataloader = dataloader_function(data_dir)\n",
        "print(len(dataloader.dataset.classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5p_96v5Ac9gF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Definition"
      ]
    },
    {
      "metadata": {
        "id": "ZPMpEmI4dDFA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Weight Initialization"
      ]
    },
    {
      "metadata": {
        "id": "dQb5wphsdBxY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(model):\n",
        "    \n",
        "    classname = model.__class__.__name__\n",
        "    \n",
        "    if classname.find('Conv') != -1:\n",
        "        model.weight.data.normal_(0.0, 0.02)\n",
        "    \n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        \n",
        "        model.weight.data.normal_(1.0, 0.02)\n",
        "        model.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KkJabarNdel5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Generator Class"
      ]
    },
    {
      "metadata": {
        "id": "VFWpRcswdi9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "          super(Generator, self).__init__()\n",
        "\n",
        "          self.main = nn.Sequential(\n",
        "              nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\n",
        "              nn.BatchNorm2d(512),\n",
        "              nn.ReLU(True),\n",
        "              nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU(True),\n",
        "              nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU(True),\n",
        "              nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(True),\n",
        "              nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
        "              nn.Tanh()\n",
        "          )\n",
        "        \n",
        "  \n",
        "  def forward(self, input):\n",
        "      \n",
        "      output = self.main(input)\n",
        "      return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLzuvSwZexar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Discriminator Class"
      ]
    },
    {
      "metadata": {
        "id": "6EA9yT7reYN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "          super(Discriminator, self).__init__()\n",
        "\n",
        "          self.main = nn.Sequential(\n",
        "              nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
        "              nn.LeakyReLU(0.2, inplace = True),\n",
        "              nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.LeakyReLU(0.2, inplace = True),\n",
        "              nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.LeakyReLU(0.2, inplace = True),\n",
        "              nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
        "              nn.BatchNorm2d(512),\n",
        "              nn.LeakyReLU(0.2, inplace = True),\n",
        "              nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
        "              nn.Sigmoid()\n",
        "          )\n",
        "\n",
        "  def forward(self, input):\n",
        "      \n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrVs2qr0fa-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Intialization"
      ]
    },
    {
      "metadata": {
        "id": "yFTLGqHMfin4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ]
    },
    {
      "metadata": {
        "id": "uzaqZOw_foAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Gnetwork = Generator().to(device)\n",
        "Gnetwork.apply(weights_init)\n",
        "\n",
        "Dnetwork = Discriminator().to(device)\n",
        "Dnetwork.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qqJl-uvIgJil",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Loss and Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "tOKcRHfHgNWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
        "\n",
        "Doptim = optim.Adam(Dnetwork.parameters(), lr=learning_rate, betas=(0.2, 0.999))\n",
        "Goptim = optim.Adam(Gnetwork.parameters(), lr=learning_rate, betas=(0.2, 0.999))\n",
        "\n",
        "Dscheduler = torch.optim.lr_scheduler.MultiStepLR(Doptim, milestones=[5,10,15,20], gamma=0.1)\n",
        "Gscheduler = torch.optim.lr_scheduler.MultiStepLR(Goptim, milestones=[5,10,15,20], gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9CeBVXphQBc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the Network"
      ]
    },
    {
      "metadata": {
        "id": "8e1jhFGNhSd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_list = []\n",
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "iterations = 0\n",
        "\n",
        "for epoch in range(25):\n",
        "    \n",
        "    Dscheduler.step()\n",
        "    Gscheduler.step()\n",
        "    \n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        Dnetwork.zero_grad()\n",
        "        real = data[0].to(device)\n",
        "        batch_size = real.size(0)\n",
        "        target = torch.full((batch_size,), 1, device=device)\n",
        "        \n",
        "        output = Dnetwork(real).view(-1)\n",
        "        error_Dreal = criterion(output, target)\n",
        "        error_Dreal.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "        fake = Gnetwork(noise)\n",
        "        target.fill_(0)\n",
        "        \n",
        "        output = Dnetwork(fake.detach()).view(-1)\n",
        "        error_Dfake = criterion(output, target)\n",
        "        error_Dfake.backward()\n",
        "        \n",
        "        error_D = error_Dreal + error_Dfake\n",
        "        Doptim.step()\n",
        "        \n",
        "        Gnetwork.zero_grad()\n",
        "        target.fill_(1)\n",
        "        output = Dnetwork(fake).view(-1)\n",
        "        \n",
        "        error_G = criterion(output, target)\n",
        "        error_G.backward()\n",
        "        Goptim.step()\n",
        "        \n",
        "        print('[%d/%d][%d/%d]\\tDiscriminator Loss: %.4f\\tGenerator Loss: %.4f'\n",
        "                  % (epoch, 25, i, len(dataloader),\n",
        "                     error_D.item(), error_G.item()))\n",
        "\n",
        "        generator_losses.append(error_G.item())\n",
        "        discriminator_losses.append(error_D.item())\n",
        "\n",
        "        if ((epoch == 25-1) and (i == len(dataloader)-1)):\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                fake = Gnetwork(fixed_noise).detach().cpu()\n",
        "            \n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0SDKn2t6ayrU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot Graphs and Generated Images"
      ]
    },
    {
      "metadata": {
        "id": "z9U5UL4ra3he",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Graphs"
      ]
    },
    {
      "metadata": {
        "id": "j-eRiruuCryJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(generator_losses,label=\"Generator\")\n",
        "plt.plot(discriminator_losses,label=\"Discriminator\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig('graph.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jrbipjila6EP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Real vs Fake Images"
      ]
    },
    {
      "metadata": {
        "id": "bnDz2MTlCvNA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.savefig('images.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}